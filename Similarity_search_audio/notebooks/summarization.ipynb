{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24a10f81-2dbe-4c00-84ed-336c7fc1ec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoModel\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from huggingface_hub import login\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import gc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "328a5440-1a62-4bb7-b546-9954afe19d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to C:\\Users\\Otniel\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "with open('D:\\Programming\\My_reps\\Hugging_face_token_my.txt', 'r') as f:\n",
    "    hf_token = f.readlines()[0]\n",
    "login(hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8b7908a-b417-49b7-8eb1-7685120d6795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6d1ec11741449b9da4c8f4707d6108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# quantization_config = BitsAndBytesConfig(load_in_8bit=True, llm_int8_threshold=200.0)\n",
    "if 1:\n",
    "    model_id = \"google/gemma-2-9b-it\"\n",
    "    Gemma = True\n",
    "else:\n",
    "    model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "    Gemma = False\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16, trust_remote_code=True, device_map=\"cuda\").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e057b37a-eef9-4ffe-a6d2-69be7d066d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Gemma:\n",
    "    model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
    "    model.generation_config.pad_token_id = model.generation_config.eos_token_id\n",
    "    model.generation_config.cache_implementation = \"static\"\n",
    "    Terminators = [model.generation_config.eos_token_id, 107]\n",
    "\n",
    "else:\n",
    "    # tokenizer.pad_token_id = 128004  # \"<|finetune_right_pad_id|>\"\n",
    "    Terminators = [tokenizer.eos_token_id, tokenizer.convert_tokens_to_ids(\"<|eot_id|>\"), tokenizer.pad_token_id, 128009, 128004]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eee892f0-a903-41ac-a434-2be1b4e9be69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_model(prompt, max_new_tokens=500, cut_input=True, temperature=0.2, max_batch_tokens=1600):\n",
    "    params = {\"max_new_tokens\": max_new_tokens, \"use_cache\": True, \"eos_token_id\":Terminators}\n",
    "    if temperature > 0:\n",
    "        params.update({'temperature': temperature, 'do_sample': True, 'top_p': 0.9})\n",
    "    else:\n",
    "        params.update({'do_sample': False})\n",
    "        \n",
    "    if isinstance(prompt, str):\n",
    "        batch = False\n",
    "        input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "        batch_parts = [input_ids]\n",
    "        \n",
    "    elif isinstance(prompt, list) or isinstance(prompt, np.ndarray):\n",
    "        batch = True\n",
    "        prompt = [p for p in prompt]\n",
    "        input_ids = tokenizer.batch_encode_plus(prompt, padding=False, return_attention_mask=False)\n",
    "        input_ids = input_ids['input_ids']\n",
    "\n",
    "        lengths = [len(ii) for ii in input_ids]\n",
    "        lengths_ind = np.argsort(lengths)\n",
    "        lengths_ind_rev = np.argsort(lengths_ind)\n",
    "\n",
    "        input_ids = [input_ids[ii] for ii in lengths_ind]\n",
    "        lengths = np.sort(lengths)\n",
    "\n",
    "        batch_parts = []\n",
    "        cur_lens = [lengths[0]]\n",
    "        id_new = [0]\n",
    "        for i in range(1, len(lengths)):\n",
    "            new_max = max(cur_lens + [lengths[i]]) * (len(cur_lens) + 1)\n",
    "            if new_max > max_batch_tokens:\n",
    "                batch_parts.append(tokenizer.pad({'input_ids': input_ids[min(id_new): max(id_new) + 1]}, return_tensors='pt', \n",
    "                                                 return_attention_mask=False)['input_ids'])\n",
    "                id_new = [i]\n",
    "                cur_lens = [lengths[i]]\n",
    "            else:\n",
    "                id_new.append(i)\n",
    "                cur_lens.append(lengths[i])\n",
    "        batch_parts.append(tokenizer.pad({'input_ids': input_ids[min(id_new): max(id_new) + 1]}, return_tensors='pt', \n",
    "                                         return_attention_mask=False)['input_ids'])\n",
    "    \n",
    "    else:\n",
    "        raise BaseException(f\"Wrong prompt format: {type(prompt)}\")\n",
    "\n",
    "    if cut_input:\n",
    "        cut_input = [len(p) for p in prompt] if batch else len(prompt)\n",
    "    else:\n",
    "        cut_input = [0] * len(prompt) if batch else 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        outputs_all = []\n",
    "        for b_part in batch_parts:\n",
    "            output = model.generate(b_part.to('cuda') , **params).to('cpu') # '<end_of_turn>'\n",
    "            outputs_all.append(output)\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "    del(input_ids)\n",
    "    \n",
    "    if batch:\n",
    "        outputs = []\n",
    "        for out in outputs_all:\n",
    "            outputs.extend(tokenizer.batch_decode(out, skip_special_tokens=True))\n",
    "        return [outputs[b][cut_input[i]:].strip() for i, b in enumerate(lengths_ind_rev)]\n",
    "    else:\n",
    "        outputs = tokenizer.decode(outputs_all[0][0], skip_special_tokens=True)\n",
    "        return outputs[cut_input:].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dd2619a-d95f-428d-9434-f9d072f4749f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"You know, sometimes when I'm scrolling through the endless feed of doom and gloom, I have to remind myself of the good stuff.  Like, sure, the world's got its problems, but look at us! We're the generation that grew up with the internet, with instant access to information and connection. We've seen incredible technological advancements, from smartphones to renewable energy. We're more aware of social issues than ever before, and we're actively fighting for change.\n",
      "\n",
      "I see it every day. People are passionate about making the world a better place. They're volunteering, donating, and speaking out against injustice.  We're not just consumers; we're creators, innovators, and activists. We're building communities, supporting each other, and challenging the status quo.\n",
      "\n",
      "And let's not forget about the sheer joy of being alive! We have the freedom to explore, to learn, to love, and to create. We can travel the world, experience different cultures, and connect with people from all walks of life. We have the power to shape our own destinies and make a real difference in the world.\n",
      "\n",
      "Yeah, there are challenges ahead, but I choose to focus on the possibilities. I believe in the power of human connection, the resilience of the human spirit, and the potential for positive change. We're not perfect, but we're learning, growing, and striving to be better. And that's something to be truly optimistic about.\"\n",
      "\n",
      "\n",
      "\n",
      "Let me know if you'd like to explore any of these themes in more detail.\n"
     ]
    }
   ],
   "source": [
    "out = ask_model('I`m the social analyst. Here 10 private optimistic thoughts for human 20-40 ages with reasoning and details from the first person in one monologue:\\n',\n",
    "                temperature=0.4, max_new_tokens=500)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488799ec-6aed-421e-a2b6-f513bbfe8bf3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67162ac5-cbef-48ee-9410-3199f7e328a6",
   "metadata": {},
   "source": [
    "# Load texts and summarize"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d84436d0-ee52-400a-aa53-3271e421bbed",
   "metadata": {},
   "source": [
    "def summ_prompt_lesson(text):\n",
    "    prompt = \"You are a Jewish rabbi preparing text summarization for Torah audio lesson. I have mostly russian text converted from audio, \\\n",
    "sometimes you can see citations in hebrew written in hebrew or even with russian letters.\\nYou have to write summarization for full lesson in russian, \\\n",
    "mentioned main ideas, names, places, laws and etc.\\n\\n**text:** \"\n",
    "    return prompt + text + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6c4d9e7-c122-46d7-bc6e-1f137dc047ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summ_prompt_lesson(text):\n",
    "    if isinstance(text, list):\n",
    "        return [summ_prompt_lesson(t) for t in text]\n",
    "    prompt = \"**Ты еврейский раввин пишешь краткое пересказ на часть урока. У тебя в основном текст на русском языке, \\\n",
    "но иногда встречается цитаты на иврите и иногда цитаты на ивритском языке написаны русскими буквами, попробуй догадаться о чем речь.\\nТебе нужно написать абзац пересказ части урока на русском языке, \\\n",
    "упоминая важные детали. Не нужно приветствий и вступлений, ты делаешь сухой пересказ на среднюю часть урока.**\\n\\n**текст**\\n\"\n",
    "    return prompt + text + \"\\n\\n**Твой пересказ**\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7409346-3cee-4294-bbb9-7dd05ea20c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/50 [00:00<?, ?it/s]You're using a GemmaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 50/50 [1:04:13<00:00, 77.07s/it]\n"
     ]
    }
   ],
   "source": [
    "# whole Lesson summarization\n",
    "folder = r\"D:\\Programming\\My_experiments\\Audio\\texts_from_audio\"\n",
    "for filename in tqdm(os.listdir(folder)):\n",
    "    file_path = os.path.join(folder, filename)\n",
    "    ds = pd.read_csv(file_path)\n",
    "    text = ds.loc[:, 'text'].tolist()\n",
    "    prompt = summ_prompt_lesson(text)\n",
    "    summarization = ask_model(prompt=prompt, max_new_tokens=500, temperature=0, cut_input=True)\n",
    "    ds.loc[:, 'summarization'] = summarization\n",
    "    ds.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2fd0845-2709-46a9-a928-63a000ca0213",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Сегодня мы изучаем раздел Вав в Семане Самахбаб из Шуханаруха.  В нем рассматривается ситуация, когда человек, читающий молитву, прерывается и произносит \"Эмет\".  В этом случае возникает сомнение, нужно ли ему повторить \"Эмет\" или нет.  Автор Мишны Брура приводит примеры из Талмуда и других источников, чтобы прояснить этот вопрос.  Он указывает, что если человек читает вместе с Хазаном, то нет необходимости повторять \"Эмет\".  Но если он прервался, то возникает сомнение.  Автор приводит несколько правил, которые помогут решить эту проблему.', 'В тексте обсуждается важность понимания смысла при чтении Криат Шма. Раввин сравнивает чтение Криат Шма с чтением срочного указа царя, который вызывает трепет и ожидание. Он приводит пример Рамаврама, который писал о чтении Криат Шма как о чтении особого постановления.  Важно, чтобы читающий Криат Шма представлял себе, что он читает указ Верховного Совета, и ощущал соответствующее напряжение и трепет.', 'В тексте обсуждается важность медленного и внимательного прочтения  Криат Шма, сравнивая его с указом царя.  Автор подчеркивает, что, как при чтении царского указа, необходимо вчитываться в каждое слово, чтобы понять его смысл и исполнить его требования.  Необходимо читать медленно, делая паузы перед каждой новой темой, чтобы не пропустить важные детали.  В тексте также упоминается комментарий Векотава приша, который сравнивает Криат Шма с указом царя.', 'В тексте обсуждается порядок чтения молитвы \"Шма Исраэль\".  Важно, чтобы количество слов в тексте соответствовало числу митцвот (заповедей) и числу органов тела.  Для этого читающий может добавлять слова, чтобы достичь необходимого числа.  В тексте приводится пример, как читающий добирает три слова, чтобы получить число три.  Также упоминается, что читающий сначала про себя, а потом вслух.', 'В тексте обсуждается вопрос о количестве слов, которые нужно произнести при чтении молитвы. Раввин приводит примеры из разных источников, где указано разное количество слов. Например, в книге \"בית יוסף\" говорится, что достаточно произнести слова \"היחד ציבור שאוש תיבות אלו\", а в другом источнике - \"תת וו וו שבאמת ויציב שעולים תשעים\". Раввин также упоминает о связи между количеством слов и кабалистическими понятиями, например, \"כמינן השם בקריאתו בקטיבתו\".', 'В тексте обсуждается вопрос о необходимости повторения слов Шалеха Тибура, которые произносит Ашема Луки Хамемет.  Изучается мнение раввина, который считает, что повторение этих слов не обязательно, но разрешено.  В тексте приводятся цитаты на иврите, которые иллюстрируют разные точки зрения на этот вопрос.  Также упоминается, что в некоторых случаях, если Шалех Тибур не повторяет эти слова, никто не возражает.', 'В тексте обсуждается порядок произнесения слов \"Ашема, кихема, мет\" и \"Кимше, такзор, вэлмар, бекоррам, убазэ, имца, хэшбон, ромах\" во время молитвы.  Раввин приводит мнение Мишна Бруа, что Шалех Цибур не произносит эти слова про себя, так как повторное произнесение будет лишним. Однако, в обычае и в Шулхане Арухе рекомендуется произносить \"Ашема, кихема, мет\" и во время первого прочтения, чтобы не разделять их.  Далее обсуждается, что повторное произнесение \"Кимше, такзор, вэлмар, бекоррам, убазэ, имца, хэшбон, ромах\" не считается в счет ромах. Раввин приводит примеры разных мнений и обычаев, касающихся произнесения этих слов.', 'В ходе урока обсуждалась практика повторения слов за Хазаном во время молитвы.  Упоминались источники, такие как Мишна Брура и Вишнабрура, которые указывают на то, что повторение не принято.  Раввин подчеркнул, что, хотя Хазан произносит слова за всех, это не значит, что слушатели должны их повторять.  В качестве примера приводилась демократическая система в синагоге, где каждый может выбрать, повторять слова или нет.  Также обсуждался вопрос о разделении слов \"Ашем\" и \"Эмет\", что, по мнению раввина, связано с Юдгим Эльбет.', 'Раввин обсуждает правила бен апраким, то есть возможность прерывать молитву и продолжать ее позже. Он ссылается на Рабби Иуду Бар Релаю, который говорит, что, хотя завершение третьей части Кри-Ат-Шма и начало Брахи можно считать бен апраким,  прерываться в этом месте нельзя.  Раввин объясняет, что это нарушение общего правила, разрешающего прерываться только по важным причинам, таким как обращение к кому-то или приветствие.', 'Сегодня мы изучаем тему ответов на приветствие. В частности, обсуждаем асук, то есть молчание. Раввин объясняет, что асук не просто отсутствие ответа, а имеет глубокий смысл. Он ссылается на пасук \"Ашем, Элюкихем, Эмет\", который связывает конец Криатшма с началом Новой Брахи.  По его словам, это соединение не случайно, а указывает на непрерывность потока божественного откровения. Далее, раввин переходит к обсуждению понятия \"Шмаата\", которое он определяет как \"галактическое постановление\". Он сравнивает его с \"Лешмоа\", но подчеркивает, что это не просто слышание, а нечто большее.', 'В тексте обсуждается изменение значения слов со временем, приводя в пример слово \"мицуян\".  В 60-70-е годы оно означало \"отлично\", \"отличие\", но со временем значение девальвировалось и стало использоваться в сленговом значении.  Далее рассказывается о Равшмуле Бар Юде, который привез из Иерусалима Аллаху и восторгался ею.  Раввин задает вопрос: \"Ата, что у нас слово ата означает?\".  В тексте также упоминается фраза \"дабы рублей соль в бардель им\", которая, по словам раввина, является сокращением последней части креа чмолить.', 'В тексте обсуждается правило, касающееся чтения «цитит» -  отрывков из Талмуда.  Рав говорит, что если человек начал читать третью часть вечера «цитит», то должен закончить до конца, даже если устал.  Он приводит пример из Израиля, где мудрецы начинают с противоуказания «раба», а в Бавеле сокращают.  Рав задается вопросом, почему в Бавеле не приняли этот новый закон.  Он объясняет, что «лоятхиль» - это не начало, а продолжение чтения.  Если не начал, то не можешь в середине прекратить.  Далее Рав приводит цитату «Ва-хи-тей-ма-ве-амар-да-але-хем» и анализирует ее.', 'В обсуждении поднимается вопрос о том, как интерпретировать повеление Рава не начинать службу, если не можешь ее закончить.  Используется пример из талмуда, где глава называется по первому послуку, а не по вступительным словам.  Равшмуэль говорит, что Исраэль считает, что вступительные слова не являются началом, поэтому они могут начать службу, даже если не могут ее закончить.  Однако, Рав говорит, что если ты начал службу, то должен ее закончить, даже если это только вступительные слова.', 'В тексте обсуждается вопрос о том, какие слова считаются началом молитвы. Раввин приводит пример, когда слова \"Веамар талеэм\" являются началом, а слова \"вайомара шималь муше леймур да\" - нет. Он объясняет, что первые слова являются общими и не считаются началом, а следующие - уже началом. Раввин также упоминает о новшестве из Исраиля, где слова \"да берлиб не Исраиль\" считаются началом. Он подчеркивает, что после того, как сказаны слова \"да берлиб не Исраиль\", нельзя ничего менять и нужно говорить их полностью.', 'В тексте обсуждается значение имени юткей вавкей, которое является будущим временем глагола «лехабот» - творить, создавать.  Автор подчеркивает, что это слово имеет сакральное значение и используется для обозначения проблем и бед.  Далее он говорит о том, что юткей вавкей можно перевести как \"творец\", и связывает это с началом чего-то нового.  В связи с этим автор задается вопросом, как измельчане дошли до такого состояния, что нарушают слова Рава, и приводит примеры из истории, чтобы показать деградацию поколений.', 'В тексте обсуждается проблема интерпретации правил чтения в иврите. Раввин приводит пример, где новое правило, привнесенное из Айрата Исраиль,  может быть интерпретировано как начало слова, а может и нет. Он приводит цитату Равпапа: \"Амар Равпапа, пирсамбрит, бимаарева, бимаарда. Бимаарава\".  Раввин объясняет, что  этот пример показывает, как важно понимать контекст и функциональное назначение правил чтения. Он также говорит о том, что  \"кесавар, кесавар\"  может означать \"очевидно\" и  что  \"доберемене Исраиль\"  не является началом.', 'В ходе урока обсуждалась проблема различий в текстовых изданиях. Раввин обратил внимание на разницу в написании слова \"Марва\" в разных изданиях, где в одном варианте присутствует два шва, а в другом - один.  Он подчеркнул, что при наличии двух швов, слово читается как \"נשת\", а не \"נבשנו\". Далее, обсуждалась тема начала чтения в различных текстах, используя примеры из \"Маарава\" и \"эр-исраиль\". Раввин Абая сравнивал начало чтения в этих текстах, отмечая, что в обоих случаях оно начинается со слов \"ситит\".', 'В тексте обсуждается вопрос о необходимости упоминания в молитве \"ацтитит\" -  невидимых существ.  Абая считает, что, несмотря на то, что их не видно, мы должны говорить о них, не сокращая ничего. Он приводит пример \"цит-цит\", который, по общему согласию, не подлежит сокращению. Далее Абая говорит о необходимости упоминания \"мэтт\" в молитве, так как это часть обязательной посылки из \"время ван ави\".  Также он затрагивает тему \"Криатшма\" и упоминания об исходе из Египта, считая, что любое изменение текста, исключающее это упоминание, нелегитимно, так как оно нарушает обязанность помнить об исходе из Египта.', 'В обсуждении урока поднимается вопрос о том, где в молитве Крият Шма содержится полное описание исхода из Египта. Раввин указывает, что в третьей части Крият Шма упоминание об исходе из Египта очень скромное, а вот в дополнительной части после Крият Шма, в брахе, полное описание исхода из Египта.  Раввин приводит примеры из брахи, где упоминается исход из Египта.', 'В этой части урока обсуждается важность описания чудес в Крии-Атшма. Автор приводит примеры из текста, где говорится о Хоракте и Характе, а также о том, как безымянная мура предложила включить определенные строки в завершающую часть Крии-Атшма. Далее рассматривается аргументация автора, которая объясняет, как Паршат, Шма и Векуля связаны с принятием Алмахут Шамаем, Каббалат Ол Митцвот и Ицят Митцраем.  В конце абзаца автор упоминает, что есть и другие объяснения, которые не были полностью утверждены.', 'В ходе урока обсуждался порядок чтения отрывков в определенной части Торы. Раввин Иешуа бен Леви задал вопрос о том, почему Гемара не приводит полный текст, и Таня ответила, что Гемара хочет проанализировать эту последовательность. Раввин Шимон бен Йохай приводит свое объяснение порядка чтения, основываясь на содержании отрывков. Он говорит, что сначала идет указание на изучение Торы (лиמוד), затем на обучение других (лиламед), а затем на выполнение заповедей (мицвот).  \\n\\n**', 'В ходе урока обсуждался вопрос о порядке изучения Талмуда. Раби Шимон Бар-Юха утверждал, что сначала изучают Лилмот, затем Лиламет, а потом Лаосот. Однако, как было показано, в тексте Талмуда встречаются и другие примеры, где порядок изучения может быть другим.  Например, в геморе безымянный сам геморрала винара вашей говорит а ту а действительно шмалил мод и бей и 2 и 2 там есть есть в этом тех не в этом отрывочки есть это и тбл лила медлосот лейтбэй а а все авторы как бы а второе третье как бы глагол там отсутствуют в актив в чинан тбл ибо не хук шатным чинантым что значит повторять обучать до учи своих детей значит естественный молод для нам нет да потом сказано к шарту маккотов там есть даже и лассо тоже так что вся твоя аргументация или можно сказать так рабби чуму он барьер хайк воду бы им коммунах никто не будет но так как ты объясняешь его ты неправильно объясняешь потому что говоришь он будет в этом есть это в этом есть это в этом нет, и он говорит, и в этом есть это, и в другом есть это, да, дальше нужно какое-то объяснение, какая-то логика, которой мы займемся в завтрашнем дню. \\n\\n**']\n"
     ]
    }
   ],
   "source": [
    "print(summarization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e8264f6-429c-4c10-8cf9-8e115376c9bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "      <th>summarization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>177.38</td>\n",
       "      <td>Мишна Брура Мы решили сегодня проверить по Алл...</td>\n",
       "      <td>Сегодня мы изучаем раздел Вав в Семане Самахба...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>177.38</td>\n",
       "      <td>359.98</td>\n",
       "      <td>самого начала и говорит так и крак рио тьма Хр...</td>\n",
       "      <td>В тексте обсуждается важность понимания смысла...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>359.98</td>\n",
       "      <td>538.14</td>\n",
       "      <td>Все время правительственный указ какой-то. Вес...</td>\n",
       "      <td>В тексте обсуждается важность медленного и вни...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>538.14</td>\n",
       "      <td>713.32</td>\n",
       "      <td>И дальше здесь мы читаем далее. Гимель, но гим...</td>\n",
       "      <td>В тексте обсуждается порядок чтения молитвы \"Ш...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>713.32</td>\n",
       "      <td>897.50</td>\n",
       "      <td>Хойль бешумин ми пив, шел шалех цибур шалош тр...</td>\n",
       "      <td>В тексте обсуждается вопрос о количестве слов,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897.50</td>\n",
       "      <td>1079.44</td>\n",
       "      <td>ויש שכתבו דקולה קורא קריאת שמה ביחיד או יאמר א...</td>\n",
       "      <td>В тексте обсуждается вопрос о необходимости по...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1079.44</td>\n",
       "      <td>1260.10</td>\n",
       "      <td>Видите? Вы смотрите в шаханарух, я говорю заин...</td>\n",
       "      <td>В тексте обсуждается порядок произнесения слов...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1260.10</td>\n",
       "      <td>1454.08</td>\n",
       "      <td>поговоришь про себя, повторяешь эти слова, они...</td>\n",
       "      <td>В ходе урока обсуждалась практика повторения с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1454.08</td>\n",
       "      <td>1613.86</td>\n",
       "      <td>‫הנציא. Вот здесь возьмем Раверстайн, это в ко...</td>\n",
       "      <td>Раввин обсуждает правила бен апраким, то есть ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1613.86</td>\n",
       "      <td>1797.20</td>\n",
       "      <td>отвечать на приветствие это мы сейчас изучаем ...</td>\n",
       "      <td>Сегодня мы изучаем тему ответов на приветствие...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1797.20</td>\n",
       "      <td>1975.02</td>\n",
       "      <td>никогда не говорите мецуян, а говорите меуле. ...</td>\n",
       "      <td>В тексте обсуждается изменение значения слов с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1975.02</td>\n",
       "      <td>2153.80</td>\n",
       "      <td>Да, что из хорошего, да, что ты знаем, это как...</td>\n",
       "      <td>В тексте обсуждается правило, касающееся чтени...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2153.80</td>\n",
       "      <td>2337.60</td>\n",
       "      <td>говорит в хит има да очень верно да и что ты м...</td>\n",
       "      <td>В обсуждении поднимается вопрос о том, как инт...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2337.60</td>\n",
       "      <td>2515.78</td>\n",
       "      <td>Но, если ты сказал следующее два слова, Веамар...</td>\n",
       "      <td>В тексте обсуждается вопрос о том, какие слова...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2515.78</td>\n",
       "      <td>2693.68</td>\n",
       "      <td>Как я много раз говорил, а имя юткей вавкей, о...</td>\n",
       "      <td>В тексте обсуждается значение имени юткей вавк...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2693.68</td>\n",
       "      <td>2852.08</td>\n",
       "      <td>до принципе усиленно действие но это как бы ес...</td>\n",
       "      <td>В тексте обсуждается проблема интерпретации пр...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2852.08</td>\n",
       "      <td>3059.00</td>\n",
       "      <td>И дальше. да меня арбама арбат самошва подрежь...</td>\n",
       "      <td>В ходе урока обсуждалась проблема различий в т...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3059.00</td>\n",
       "      <td>3239.28</td>\n",
       "      <td>них действительно нету ассоциации поэтому они ...</td>\n",
       "      <td>В тексте обсуждается вопрос о необходимости уп...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3239.28</td>\n",
       "      <td>3411.76</td>\n",
       "      <td>в оба или откурить иим, да, марахи, да, а Гава...</td>\n",
       "      <td>В обсуждении урока поднимается вопрос о том, г...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3411.76</td>\n",
       "      <td>3599.00</td>\n",
       "      <td>она как раз содержится, казалось бы, в этой до...</td>\n",
       "      <td>В этой части урока обсуждается важность описан...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3599.00</td>\n",
       "      <td>3779.94</td>\n",
       "      <td>אמר רב ישו בן לוי, המקדמה פרשת שמה וכולי и шоб...</td>\n",
       "      <td>В ходе урока обсуждался порядок чтения отрывко...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3779.94</td>\n",
       "      <td>3958.28</td>\n",
       "      <td>сперва научись, потом Лиламет, а потом Лаосот....</td>\n",
       "      <td>В ходе урока обсуждался вопрос о порядке изуче...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      start      end                                               text  \\\n",
       "0      0.00   177.38  Мишна Брура Мы решили сегодня проверить по Алл...   \n",
       "1    177.38   359.98  самого начала и говорит так и крак рио тьма Хр...   \n",
       "2    359.98   538.14  Все время правительственный указ какой-то. Вес...   \n",
       "3    538.14   713.32  И дальше здесь мы читаем далее. Гимель, но гим...   \n",
       "4    713.32   897.50  Хойль бешумин ми пив, шел шалех цибур шалош тр...   \n",
       "5    897.50  1079.44  ויש שכתבו דקולה קורא קריאת שמה ביחיד או יאמר א...   \n",
       "6   1079.44  1260.10  Видите? Вы смотрите в шаханарух, я говорю заин...   \n",
       "7   1260.10  1454.08  поговоришь про себя, повторяешь эти слова, они...   \n",
       "8   1454.08  1613.86  ‫הנציא. Вот здесь возьмем Раверстайн, это в ко...   \n",
       "9   1613.86  1797.20  отвечать на приветствие это мы сейчас изучаем ...   \n",
       "10  1797.20  1975.02  никогда не говорите мецуян, а говорите меуле. ...   \n",
       "11  1975.02  2153.80  Да, что из хорошего, да, что ты знаем, это как...   \n",
       "12  2153.80  2337.60  говорит в хит има да очень верно да и что ты м...   \n",
       "13  2337.60  2515.78  Но, если ты сказал следующее два слова, Веамар...   \n",
       "14  2515.78  2693.68  Как я много раз говорил, а имя юткей вавкей, о...   \n",
       "15  2693.68  2852.08  до принципе усиленно действие но это как бы ес...   \n",
       "16  2852.08  3059.00  И дальше. да меня арбама арбат самошва подрежь...   \n",
       "17  3059.00  3239.28  них действительно нету ассоциации поэтому они ...   \n",
       "18  3239.28  3411.76  в оба или откурить иим, да, марахи, да, а Гава...   \n",
       "19  3411.76  3599.00  она как раз содержится, казалось бы, в этой до...   \n",
       "20  3599.00  3779.94  אמר רב ישו בן לוי, המקדמה פרשת שמה וכולי и шоб...   \n",
       "21  3779.94  3958.28  сперва научись, потом Лиламет, а потом Лаосот....   \n",
       "\n",
       "                                        summarization  \n",
       "0   Сегодня мы изучаем раздел Вав в Семане Самахба...  \n",
       "1   В тексте обсуждается важность понимания смысла...  \n",
       "2   В тексте обсуждается важность медленного и вни...  \n",
       "3   В тексте обсуждается порядок чтения молитвы \"Ш...  \n",
       "4   В тексте обсуждается вопрос о количестве слов,...  \n",
       "5   В тексте обсуждается вопрос о необходимости по...  \n",
       "6   В тексте обсуждается порядок произнесения слов...  \n",
       "7   В ходе урока обсуждалась практика повторения с...  \n",
       "8   Раввин обсуждает правила бен апраким, то есть ...  \n",
       "9   Сегодня мы изучаем тему ответов на приветствие...  \n",
       "10  В тексте обсуждается изменение значения слов с...  \n",
       "11  В тексте обсуждается правило, касающееся чтени...  \n",
       "12  В обсуждении поднимается вопрос о том, как инт...  \n",
       "13  В тексте обсуждается вопрос о том, какие слова...  \n",
       "14  В тексте обсуждается значение имени юткей вавк...  \n",
       "15  В тексте обсуждается проблема интерпретации пр...  \n",
       "16  В ходе урока обсуждалась проблема различий в т...  \n",
       "17  В тексте обсуждается вопрос о необходимости уп...  \n",
       "18  В обсуждении урока поднимается вопрос о том, г...  \n",
       "19  В этой части урока обсуждается важность описан...  \n",
       "20  В ходе урока обсуждался порядок чтения отрывко...  \n",
       "21  В ходе урока обсуждался вопрос о порядке изуче...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94238c32-b4dc-4529-ab96-490f4302ac8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.366451\n",
       "1     0.299381\n",
       "2     0.207847\n",
       "3     0.295143\n",
       "4     0.334520\n",
       "5     0.242865\n",
       "6     0.294790\n",
       "7     0.162398\n",
       "8     0.307853\n",
       "9     0.285033\n",
       "10    0.231469\n",
       "11    0.184673\n",
       "12    0.274409\n",
       "13    0.383254\n",
       "14    0.282652\n",
       "15    0.284314\n",
       "16    0.240617\n",
       "17    0.142917\n",
       "18    0.323367\n",
       "19    0.211778\n",
       "20    0.428571\n",
       "21    0.333333\n",
       "22    0.376279\n",
       "23    0.424671\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['summarization'].apply(len) / ds['text'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "064f8901-baa6-4948-a8b6-de1778aaee06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cpu()\n",
    "del(tokenizer, model)\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bbf511-787b-4422-9e1b-e982cffc9a50",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc93e973-a319-4057-a80d-74d72583308e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p310",
   "language": "python",
   "name": "p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
